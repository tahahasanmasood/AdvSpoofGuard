{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is used for converting videos to images which are helpful in training CycleGAN and generating TSNEs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from torchvision import transforms, models\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label_real = 0\n",
    "class_label_attack = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_videos = '/dataset/videos'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_samples(path, class_label, transform, save_path, counter_dict):\n",
    "    frames = read_all_frames(path)\n",
    "    total_frames = list(range(0, frames.shape[0], 1)) # Read all frames of video\n",
    "    selected_samples = random.sample(total_frames, 1) # Extract one randomly frame from each video. Change 1 to any desired frame whatever needed for extraction. For Cycle-GAN training we need more frames but for TSNE 1 frame is enough.\n",
    "    samples = []\n",
    "\n",
    "    for sample_idx in selected_samples:\n",
    "        frame = transform(frames[sample_idx].squeeze())\n",
    "        label = class_label\n",
    "\n",
    "        # Get the counter for the current class\n",
    "        counter = counter_dict.get(class_label, 0)\n",
    "\n",
    "        # Save the frame to disk with a unique filename\n",
    "        save_filename = f\"{class_label}_{counter}_{sample_idx}.png\"\n",
    "        save_filepath = os.path.join(save_path, save_filename)\n",
    "        cv2.imwrite(save_filepath, frame.numpy().transpose(1, 2, 0) * 255)\n",
    "\n",
    "        # Update the counter for the current class\n",
    "        counter_dict[class_label] = counter + 1\n",
    "\n",
    "        samples.append((frame, label))\n",
    "\n",
    "    return samples\n",
    "\n",
    "def read_all_frames(video_path): # reads all frames from a particular video and converts them to PyTorch tensors.\n",
    "    frame_list = []\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    success = True\n",
    "    while success:\n",
    "        success, frame = video.read()\n",
    "        if success:\n",
    "            frame = cv2.resize(frame, (256, 256), interpolation=cv2.INTER_AREA) #framesize kept 256 x 256\n",
    "            frame_list.append(frame)\n",
    "    frame_list = np.array(frame_list)\n",
    "    return frame_list\n",
    "\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, data_path, class_label, save_path, counter_dict):\n",
    "        self.data_path = data_path #path for directory containing video files\n",
    "        self.video_files = [file for file in os.listdir(data_path) if file.endswith('.avi')] #list of video files in the specified directory #.mov for RA and RM, .avi for OULU-NPU, .mp4 for RY\n",
    "        self.class_label = class_label #manually assign class_label for your desired class while loading\n",
    "        self.data_length = len(self.video_files) \n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "        self.save_path = save_path # Added save_path parameter\n",
    "        self.counter_dict = counter_dict\n",
    "\n",
    "    def __len__(self): # returns the total number of samples in the dataset\n",
    "        return self.data_length\n",
    "\n",
    "    def __getitem__(self, idx): # loads and returns a sample from the dataset at the given index\n",
    "        file = self.video_files[idx]\n",
    "        path = os.path.join(self.data_path, file)\n",
    "        frames= load_samples(path, self.class_label, self.transform, self.save_path, self.counter_dict) \n",
    "\n",
    "        return frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Dataset Videos, Assigning Label, & Images Path  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_dict = {}\n",
    "save_path_images = '/folder/images'\n",
    "save_dataset = VideoDataset(data_path_videos, class_label, save_path_images, counter_dict) # Assign class_label_real = 0 or class_label_attack = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting Images to Desired Save Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_samples = []\n",
    "for idx in range(len(save_dataset)):\n",
    "    samples = save_dataset[idx]\n",
    "    all_samples.extend(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Total No. of Saved Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(os.listdir(save_path_images)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt_fpad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
