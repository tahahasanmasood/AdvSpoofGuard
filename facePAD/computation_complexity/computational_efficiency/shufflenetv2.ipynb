{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taha/anaconda3/envs/pt_fpad/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchprofile\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/taha/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/home/taha/anaconda3/envs/pt_fpad/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/taha/anaconda3/envs/pt_fpad/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ShuffleNet_V2_X1_0_Weights.IMAGENET1K_V1`. You can also use `weights=ShuffleNet_V2_X1_0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [64, 24, 128, 128]             648\n",
      "       BatchNorm2d-2         [64, 24, 128, 128]              48\n",
      "              ReLU-3         [64, 24, 128, 128]               0\n",
      "         MaxPool2d-4           [64, 24, 64, 64]               0\n",
      "            Conv2d-5           [64, 24, 32, 32]             216\n",
      "       BatchNorm2d-6           [64, 24, 32, 32]              48\n",
      "            Conv2d-7           [64, 58, 32, 32]           1,392\n",
      "       BatchNorm2d-8           [64, 58, 32, 32]             116\n",
      "              ReLU-9           [64, 58, 32, 32]               0\n",
      "           Conv2d-10           [64, 58, 64, 64]           1,392\n",
      "      BatchNorm2d-11           [64, 58, 64, 64]             116\n",
      "             ReLU-12           [64, 58, 64, 64]               0\n",
      "           Conv2d-13           [64, 58, 32, 32]             522\n",
      "      BatchNorm2d-14           [64, 58, 32, 32]             116\n",
      "           Conv2d-15           [64, 58, 32, 32]           3,364\n",
      "      BatchNorm2d-16           [64, 58, 32, 32]             116\n",
      "             ReLU-17           [64, 58, 32, 32]               0\n",
      " InvertedResidual-18          [64, 116, 32, 32]               0\n",
      "           Conv2d-19           [64, 58, 32, 32]           3,364\n",
      "      BatchNorm2d-20           [64, 58, 32, 32]             116\n",
      "             ReLU-21           [64, 58, 32, 32]               0\n",
      "           Conv2d-22           [64, 58, 32, 32]             522\n",
      "      BatchNorm2d-23           [64, 58, 32, 32]             116\n",
      "           Conv2d-24           [64, 58, 32, 32]           3,364\n",
      "      BatchNorm2d-25           [64, 58, 32, 32]             116\n",
      "             ReLU-26           [64, 58, 32, 32]               0\n",
      " InvertedResidual-27          [64, 116, 32, 32]               0\n",
      "           Conv2d-28           [64, 58, 32, 32]           3,364\n",
      "      BatchNorm2d-29           [64, 58, 32, 32]             116\n",
      "             ReLU-30           [64, 58, 32, 32]               0\n",
      "           Conv2d-31           [64, 58, 32, 32]             522\n",
      "      BatchNorm2d-32           [64, 58, 32, 32]             116\n",
      "           Conv2d-33           [64, 58, 32, 32]           3,364\n",
      "      BatchNorm2d-34           [64, 58, 32, 32]             116\n",
      "             ReLU-35           [64, 58, 32, 32]               0\n",
      " InvertedResidual-36          [64, 116, 32, 32]               0\n",
      "           Conv2d-37           [64, 58, 32, 32]           3,364\n",
      "      BatchNorm2d-38           [64, 58, 32, 32]             116\n",
      "             ReLU-39           [64, 58, 32, 32]               0\n",
      "           Conv2d-40           [64, 58, 32, 32]             522\n",
      "      BatchNorm2d-41           [64, 58, 32, 32]             116\n",
      "           Conv2d-42           [64, 58, 32, 32]           3,364\n",
      "      BatchNorm2d-43           [64, 58, 32, 32]             116\n",
      "             ReLU-44           [64, 58, 32, 32]               0\n",
      " InvertedResidual-45          [64, 116, 32, 32]               0\n",
      "           Conv2d-46          [64, 116, 16, 16]           1,044\n",
      "      BatchNorm2d-47          [64, 116, 16, 16]             232\n",
      "           Conv2d-48          [64, 116, 16, 16]          13,456\n",
      "      BatchNorm2d-49          [64, 116, 16, 16]             232\n",
      "             ReLU-50          [64, 116, 16, 16]               0\n",
      "           Conv2d-51          [64, 116, 32, 32]          13,456\n",
      "      BatchNorm2d-52          [64, 116, 32, 32]             232\n",
      "             ReLU-53          [64, 116, 32, 32]               0\n",
      "           Conv2d-54          [64, 116, 16, 16]           1,044\n",
      "      BatchNorm2d-55          [64, 116, 16, 16]             232\n",
      "           Conv2d-56          [64, 116, 16, 16]          13,456\n",
      "      BatchNorm2d-57          [64, 116, 16, 16]             232\n",
      "             ReLU-58          [64, 116, 16, 16]               0\n",
      " InvertedResidual-59          [64, 232, 16, 16]               0\n",
      "           Conv2d-60          [64, 116, 16, 16]          13,456\n",
      "      BatchNorm2d-61          [64, 116, 16, 16]             232\n",
      "             ReLU-62          [64, 116, 16, 16]               0\n",
      "           Conv2d-63          [64, 116, 16, 16]           1,044\n",
      "      BatchNorm2d-64          [64, 116, 16, 16]             232\n",
      "           Conv2d-65          [64, 116, 16, 16]          13,456\n",
      "      BatchNorm2d-66          [64, 116, 16, 16]             232\n",
      "             ReLU-67          [64, 116, 16, 16]               0\n",
      " InvertedResidual-68          [64, 232, 16, 16]               0\n",
      "           Conv2d-69          [64, 116, 16, 16]          13,456\n",
      "      BatchNorm2d-70          [64, 116, 16, 16]             232\n",
      "             ReLU-71          [64, 116, 16, 16]               0\n",
      "           Conv2d-72          [64, 116, 16, 16]           1,044\n",
      "      BatchNorm2d-73          [64, 116, 16, 16]             232\n",
      "           Conv2d-74          [64, 116, 16, 16]          13,456\n",
      "      BatchNorm2d-75          [64, 116, 16, 16]             232\n",
      "             ReLU-76          [64, 116, 16, 16]               0\n",
      " InvertedResidual-77          [64, 232, 16, 16]               0\n",
      "           Conv2d-78          [64, 116, 16, 16]          13,456\n",
      "      BatchNorm2d-79          [64, 116, 16, 16]             232\n",
      "             ReLU-80          [64, 116, 16, 16]               0\n",
      "           Conv2d-81          [64, 116, 16, 16]           1,044\n",
      "      BatchNorm2d-82          [64, 116, 16, 16]             232\n",
      "           Conv2d-83          [64, 116, 16, 16]          13,456\n",
      "      BatchNorm2d-84          [64, 116, 16, 16]             232\n",
      "             ReLU-85          [64, 116, 16, 16]               0\n",
      " InvertedResidual-86          [64, 232, 16, 16]               0\n",
      "           Conv2d-87          [64, 116, 16, 16]          13,456\n",
      "      BatchNorm2d-88          [64, 116, 16, 16]             232\n",
      "             ReLU-89          [64, 116, 16, 16]               0\n",
      "           Conv2d-90          [64, 116, 16, 16]           1,044\n",
      "      BatchNorm2d-91          [64, 116, 16, 16]             232\n",
      "           Conv2d-92          [64, 116, 16, 16]          13,456\n",
      "      BatchNorm2d-93          [64, 116, 16, 16]             232\n",
      "             ReLU-94          [64, 116, 16, 16]               0\n",
      " InvertedResidual-95          [64, 232, 16, 16]               0\n",
      "           Conv2d-96          [64, 116, 16, 16]          13,456\n",
      "      BatchNorm2d-97          [64, 116, 16, 16]             232\n",
      "             ReLU-98          [64, 116, 16, 16]               0\n",
      "           Conv2d-99          [64, 116, 16, 16]           1,044\n",
      "     BatchNorm2d-100          [64, 116, 16, 16]             232\n",
      "          Conv2d-101          [64, 116, 16, 16]          13,456\n",
      "     BatchNorm2d-102          [64, 116, 16, 16]             232\n",
      "            ReLU-103          [64, 116, 16, 16]               0\n",
      "InvertedResidual-104          [64, 232, 16, 16]               0\n",
      "          Conv2d-105          [64, 116, 16, 16]          13,456\n",
      "     BatchNorm2d-106          [64, 116, 16, 16]             232\n",
      "            ReLU-107          [64, 116, 16, 16]               0\n",
      "          Conv2d-108          [64, 116, 16, 16]           1,044\n",
      "     BatchNorm2d-109          [64, 116, 16, 16]             232\n",
      "          Conv2d-110          [64, 116, 16, 16]          13,456\n",
      "     BatchNorm2d-111          [64, 116, 16, 16]             232\n",
      "            ReLU-112          [64, 116, 16, 16]               0\n",
      "InvertedResidual-113          [64, 232, 16, 16]               0\n",
      "          Conv2d-114          [64, 116, 16, 16]          13,456\n",
      "     BatchNorm2d-115          [64, 116, 16, 16]             232\n",
      "            ReLU-116          [64, 116, 16, 16]               0\n",
      "          Conv2d-117          [64, 116, 16, 16]           1,044\n",
      "     BatchNorm2d-118          [64, 116, 16, 16]             232\n",
      "          Conv2d-119          [64, 116, 16, 16]          13,456\n",
      "     BatchNorm2d-120          [64, 116, 16, 16]             232\n",
      "            ReLU-121          [64, 116, 16, 16]               0\n",
      "InvertedResidual-122          [64, 232, 16, 16]               0\n",
      "          Conv2d-123            [64, 232, 8, 8]           2,088\n",
      "     BatchNorm2d-124            [64, 232, 8, 8]             464\n",
      "          Conv2d-125            [64, 232, 8, 8]          53,824\n",
      "     BatchNorm2d-126            [64, 232, 8, 8]             464\n",
      "            ReLU-127            [64, 232, 8, 8]               0\n",
      "          Conv2d-128          [64, 232, 16, 16]          53,824\n",
      "     BatchNorm2d-129          [64, 232, 16, 16]             464\n",
      "            ReLU-130          [64, 232, 16, 16]               0\n",
      "          Conv2d-131            [64, 232, 8, 8]           2,088\n",
      "     BatchNorm2d-132            [64, 232, 8, 8]             464\n",
      "          Conv2d-133            [64, 232, 8, 8]          53,824\n",
      "     BatchNorm2d-134            [64, 232, 8, 8]             464\n",
      "            ReLU-135            [64, 232, 8, 8]               0\n",
      "InvertedResidual-136            [64, 464, 8, 8]               0\n",
      "          Conv2d-137            [64, 232, 8, 8]          53,824\n",
      "     BatchNorm2d-138            [64, 232, 8, 8]             464\n",
      "            ReLU-139            [64, 232, 8, 8]               0\n",
      "          Conv2d-140            [64, 232, 8, 8]           2,088\n",
      "     BatchNorm2d-141            [64, 232, 8, 8]             464\n",
      "          Conv2d-142            [64, 232, 8, 8]          53,824\n",
      "     BatchNorm2d-143            [64, 232, 8, 8]             464\n",
      "            ReLU-144            [64, 232, 8, 8]               0\n",
      "InvertedResidual-145            [64, 464, 8, 8]               0\n",
      "          Conv2d-146            [64, 232, 8, 8]          53,824\n",
      "     BatchNorm2d-147            [64, 232, 8, 8]             464\n",
      "            ReLU-148            [64, 232, 8, 8]               0\n",
      "          Conv2d-149            [64, 232, 8, 8]           2,088\n",
      "     BatchNorm2d-150            [64, 232, 8, 8]             464\n",
      "          Conv2d-151            [64, 232, 8, 8]          53,824\n",
      "     BatchNorm2d-152            [64, 232, 8, 8]             464\n",
      "            ReLU-153            [64, 232, 8, 8]               0\n",
      "InvertedResidual-154            [64, 464, 8, 8]               0\n",
      "          Conv2d-155            [64, 232, 8, 8]          53,824\n",
      "     BatchNorm2d-156            [64, 232, 8, 8]             464\n",
      "            ReLU-157            [64, 232, 8, 8]               0\n",
      "          Conv2d-158            [64, 232, 8, 8]           2,088\n",
      "     BatchNorm2d-159            [64, 232, 8, 8]             464\n",
      "          Conv2d-160            [64, 232, 8, 8]          53,824\n",
      "     BatchNorm2d-161            [64, 232, 8, 8]             464\n",
      "            ReLU-162            [64, 232, 8, 8]               0\n",
      "InvertedResidual-163            [64, 464, 8, 8]               0\n",
      "          Conv2d-164           [64, 1024, 8, 8]         475,136\n",
      "     BatchNorm2d-165           [64, 1024, 8, 8]           2,048\n",
      "            ReLU-166           [64, 1024, 8, 8]               0\n",
      "          Linear-167                    [64, 2]           2,050\n",
      "================================================================\n",
      "Total params: 1,255,654\n",
      "Trainable params: 1,255,654\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 48.00\n",
      "Forward/backward pass size (MB): 4006.50\n",
      "Params size (MB): 4.79\n",
      "Estimated Total Size (MB): 4059.29\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'shufflenet_v2_x1_0', pretrained=True)\n",
    "model.fc = nn.Linear(in_features=1024, out_features=2)\n",
    "model.to(device)\n",
    "summary(model, (3, 256, 256), batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.randn(1, 3, 256, 256).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/zhijian-liu/torchprofile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warm up the GPU\n",
    "with torch.no_grad():\n",
    "    for _ in range(10):\n",
    "        _ = model(input_tensor)\n",
    "\n",
    "# Measure FLOPs\n",
    "with torch.no_grad():\n",
    "    macs = torchprofile.profile_macs(model, args=(input_tensor,))\n",
    "    flops = 2 * macs  # Convert MACs to FLOPs\n",
    "\n",
    "# Measure inference time\n",
    "with torch.no_grad():\n",
    "    start_time = time.time()\n",
    "    for _ in range(100):  # Run multiple inferences\n",
    "        _ = model(input_tensor)\n",
    "    end_time = time.time()\n",
    "\n",
    "# Calculate elapsed time per inference and throughput\n",
    "elapsed_time = (end_time - start_time) / 100  # Average inference time per run\n",
    "tops = (flops / elapsed_time) / 1e12  # Throughput in TOPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLOPs: 0.38 GFLOPs, Inference Time: 10.93 ms, Throughput: 0.03 TOPs\n"
     ]
    }
   ],
   "source": [
    "print(f\"FLOPs: {flops / 1e9:.2f} GFLOPs, \"\n",
    "        f\"Inference Time: {elapsed_time * 1000:.2f} ms, Throughput: {tops:.2f} TOPs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt_fpad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
