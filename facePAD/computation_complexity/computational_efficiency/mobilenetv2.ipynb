{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taha/anaconda3/envs/pt_fpad/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchprofile\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taha/anaconda3/envs/pt_fpad/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/taha/anaconda3/envs/pt_fpad/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [64, 32, 128, 128]             864\n",
      "       BatchNorm2d-2         [64, 32, 128, 128]              64\n",
      "             ReLU6-3         [64, 32, 128, 128]               0\n",
      "            Conv2d-4         [64, 32, 128, 128]             288\n",
      "       BatchNorm2d-5         [64, 32, 128, 128]              64\n",
      "             ReLU6-6         [64, 32, 128, 128]               0\n",
      "            Conv2d-7         [64, 16, 128, 128]             512\n",
      "       BatchNorm2d-8         [64, 16, 128, 128]              32\n",
      "  InvertedResidual-9         [64, 16, 128, 128]               0\n",
      "           Conv2d-10         [64, 96, 128, 128]           1,536\n",
      "      BatchNorm2d-11         [64, 96, 128, 128]             192\n",
      "            ReLU6-12         [64, 96, 128, 128]               0\n",
      "           Conv2d-13           [64, 96, 64, 64]             864\n",
      "      BatchNorm2d-14           [64, 96, 64, 64]             192\n",
      "            ReLU6-15           [64, 96, 64, 64]               0\n",
      "           Conv2d-16           [64, 24, 64, 64]           2,304\n",
      "      BatchNorm2d-17           [64, 24, 64, 64]              48\n",
      " InvertedResidual-18           [64, 24, 64, 64]               0\n",
      "           Conv2d-19          [64, 144, 64, 64]           3,456\n",
      "      BatchNorm2d-20          [64, 144, 64, 64]             288\n",
      "            ReLU6-21          [64, 144, 64, 64]               0\n",
      "           Conv2d-22          [64, 144, 64, 64]           1,296\n",
      "      BatchNorm2d-23          [64, 144, 64, 64]             288\n",
      "            ReLU6-24          [64, 144, 64, 64]               0\n",
      "           Conv2d-25           [64, 24, 64, 64]           3,456\n",
      "      BatchNorm2d-26           [64, 24, 64, 64]              48\n",
      " InvertedResidual-27           [64, 24, 64, 64]               0\n",
      "           Conv2d-28          [64, 144, 64, 64]           3,456\n",
      "      BatchNorm2d-29          [64, 144, 64, 64]             288\n",
      "            ReLU6-30          [64, 144, 64, 64]               0\n",
      "           Conv2d-31          [64, 144, 32, 32]           1,296\n",
      "      BatchNorm2d-32          [64, 144, 32, 32]             288\n",
      "            ReLU6-33          [64, 144, 32, 32]               0\n",
      "           Conv2d-34           [64, 32, 32, 32]           4,608\n",
      "      BatchNorm2d-35           [64, 32, 32, 32]              64\n",
      " InvertedResidual-36           [64, 32, 32, 32]               0\n",
      "           Conv2d-37          [64, 192, 32, 32]           6,144\n",
      "      BatchNorm2d-38          [64, 192, 32, 32]             384\n",
      "            ReLU6-39          [64, 192, 32, 32]               0\n",
      "           Conv2d-40          [64, 192, 32, 32]           1,728\n",
      "      BatchNorm2d-41          [64, 192, 32, 32]             384\n",
      "            ReLU6-42          [64, 192, 32, 32]               0\n",
      "           Conv2d-43           [64, 32, 32, 32]           6,144\n",
      "      BatchNorm2d-44           [64, 32, 32, 32]              64\n",
      " InvertedResidual-45           [64, 32, 32, 32]               0\n",
      "           Conv2d-46          [64, 192, 32, 32]           6,144\n",
      "      BatchNorm2d-47          [64, 192, 32, 32]             384\n",
      "            ReLU6-48          [64, 192, 32, 32]               0\n",
      "           Conv2d-49          [64, 192, 32, 32]           1,728\n",
      "      BatchNorm2d-50          [64, 192, 32, 32]             384\n",
      "            ReLU6-51          [64, 192, 32, 32]               0\n",
      "           Conv2d-52           [64, 32, 32, 32]           6,144\n",
      "      BatchNorm2d-53           [64, 32, 32, 32]              64\n",
      " InvertedResidual-54           [64, 32, 32, 32]               0\n",
      "           Conv2d-55          [64, 192, 32, 32]           6,144\n",
      "      BatchNorm2d-56          [64, 192, 32, 32]             384\n",
      "            ReLU6-57          [64, 192, 32, 32]               0\n",
      "           Conv2d-58          [64, 192, 16, 16]           1,728\n",
      "      BatchNorm2d-59          [64, 192, 16, 16]             384\n",
      "            ReLU6-60          [64, 192, 16, 16]               0\n",
      "           Conv2d-61           [64, 64, 16, 16]          12,288\n",
      "      BatchNorm2d-62           [64, 64, 16, 16]             128\n",
      " InvertedResidual-63           [64, 64, 16, 16]               0\n",
      "           Conv2d-64          [64, 384, 16, 16]          24,576\n",
      "      BatchNorm2d-65          [64, 384, 16, 16]             768\n",
      "            ReLU6-66          [64, 384, 16, 16]               0\n",
      "           Conv2d-67          [64, 384, 16, 16]           3,456\n",
      "      BatchNorm2d-68          [64, 384, 16, 16]             768\n",
      "            ReLU6-69          [64, 384, 16, 16]               0\n",
      "           Conv2d-70           [64, 64, 16, 16]          24,576\n",
      "      BatchNorm2d-71           [64, 64, 16, 16]             128\n",
      " InvertedResidual-72           [64, 64, 16, 16]               0\n",
      "           Conv2d-73          [64, 384, 16, 16]          24,576\n",
      "      BatchNorm2d-74          [64, 384, 16, 16]             768\n",
      "            ReLU6-75          [64, 384, 16, 16]               0\n",
      "           Conv2d-76          [64, 384, 16, 16]           3,456\n",
      "      BatchNorm2d-77          [64, 384, 16, 16]             768\n",
      "            ReLU6-78          [64, 384, 16, 16]               0\n",
      "           Conv2d-79           [64, 64, 16, 16]          24,576\n",
      "      BatchNorm2d-80           [64, 64, 16, 16]             128\n",
      " InvertedResidual-81           [64, 64, 16, 16]               0\n",
      "           Conv2d-82          [64, 384, 16, 16]          24,576\n",
      "      BatchNorm2d-83          [64, 384, 16, 16]             768\n",
      "            ReLU6-84          [64, 384, 16, 16]               0\n",
      "           Conv2d-85          [64, 384, 16, 16]           3,456\n",
      "      BatchNorm2d-86          [64, 384, 16, 16]             768\n",
      "            ReLU6-87          [64, 384, 16, 16]               0\n",
      "           Conv2d-88           [64, 64, 16, 16]          24,576\n",
      "      BatchNorm2d-89           [64, 64, 16, 16]             128\n",
      " InvertedResidual-90           [64, 64, 16, 16]               0\n",
      "           Conv2d-91          [64, 384, 16, 16]          24,576\n",
      "      BatchNorm2d-92          [64, 384, 16, 16]             768\n",
      "            ReLU6-93          [64, 384, 16, 16]               0\n",
      "           Conv2d-94          [64, 384, 16, 16]           3,456\n",
      "      BatchNorm2d-95          [64, 384, 16, 16]             768\n",
      "            ReLU6-96          [64, 384, 16, 16]               0\n",
      "           Conv2d-97           [64, 96, 16, 16]          36,864\n",
      "      BatchNorm2d-98           [64, 96, 16, 16]             192\n",
      " InvertedResidual-99           [64, 96, 16, 16]               0\n",
      "          Conv2d-100          [64, 576, 16, 16]          55,296\n",
      "     BatchNorm2d-101          [64, 576, 16, 16]           1,152\n",
      "           ReLU6-102          [64, 576, 16, 16]               0\n",
      "          Conv2d-103          [64, 576, 16, 16]           5,184\n",
      "     BatchNorm2d-104          [64, 576, 16, 16]           1,152\n",
      "           ReLU6-105          [64, 576, 16, 16]               0\n",
      "          Conv2d-106           [64, 96, 16, 16]          55,296\n",
      "     BatchNorm2d-107           [64, 96, 16, 16]             192\n",
      "InvertedResidual-108           [64, 96, 16, 16]               0\n",
      "          Conv2d-109          [64, 576, 16, 16]          55,296\n",
      "     BatchNorm2d-110          [64, 576, 16, 16]           1,152\n",
      "           ReLU6-111          [64, 576, 16, 16]               0\n",
      "          Conv2d-112          [64, 576, 16, 16]           5,184\n",
      "     BatchNorm2d-113          [64, 576, 16, 16]           1,152\n",
      "           ReLU6-114          [64, 576, 16, 16]               0\n",
      "          Conv2d-115           [64, 96, 16, 16]          55,296\n",
      "     BatchNorm2d-116           [64, 96, 16, 16]             192\n",
      "InvertedResidual-117           [64, 96, 16, 16]               0\n",
      "          Conv2d-118          [64, 576, 16, 16]          55,296\n",
      "     BatchNorm2d-119          [64, 576, 16, 16]           1,152\n",
      "           ReLU6-120          [64, 576, 16, 16]               0\n",
      "          Conv2d-121            [64, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-122            [64, 576, 8, 8]           1,152\n",
      "           ReLU6-123            [64, 576, 8, 8]               0\n",
      "          Conv2d-124            [64, 160, 8, 8]          92,160\n",
      "     BatchNorm2d-125            [64, 160, 8, 8]             320\n",
      "InvertedResidual-126            [64, 160, 8, 8]               0\n",
      "          Conv2d-127            [64, 960, 8, 8]         153,600\n",
      "     BatchNorm2d-128            [64, 960, 8, 8]           1,920\n",
      "           ReLU6-129            [64, 960, 8, 8]               0\n",
      "          Conv2d-130            [64, 960, 8, 8]           8,640\n",
      "     BatchNorm2d-131            [64, 960, 8, 8]           1,920\n",
      "           ReLU6-132            [64, 960, 8, 8]               0\n",
      "          Conv2d-133            [64, 160, 8, 8]         153,600\n",
      "     BatchNorm2d-134            [64, 160, 8, 8]             320\n",
      "InvertedResidual-135            [64, 160, 8, 8]               0\n",
      "          Conv2d-136            [64, 960, 8, 8]         153,600\n",
      "     BatchNorm2d-137            [64, 960, 8, 8]           1,920\n",
      "           ReLU6-138            [64, 960, 8, 8]               0\n",
      "          Conv2d-139            [64, 960, 8, 8]           8,640\n",
      "     BatchNorm2d-140            [64, 960, 8, 8]           1,920\n",
      "           ReLU6-141            [64, 960, 8, 8]               0\n",
      "          Conv2d-142            [64, 160, 8, 8]         153,600\n",
      "     BatchNorm2d-143            [64, 160, 8, 8]             320\n",
      "InvertedResidual-144            [64, 160, 8, 8]               0\n",
      "          Conv2d-145            [64, 960, 8, 8]         153,600\n",
      "     BatchNorm2d-146            [64, 960, 8, 8]           1,920\n",
      "           ReLU6-147            [64, 960, 8, 8]               0\n",
      "          Conv2d-148            [64, 960, 8, 8]           8,640\n",
      "     BatchNorm2d-149            [64, 960, 8, 8]           1,920\n",
      "           ReLU6-150            [64, 960, 8, 8]               0\n",
      "          Conv2d-151            [64, 320, 8, 8]         307,200\n",
      "     BatchNorm2d-152            [64, 320, 8, 8]             640\n",
      "InvertedResidual-153            [64, 320, 8, 8]               0\n",
      "          Conv2d-154           [64, 1280, 8, 8]         409,600\n",
      "     BatchNorm2d-155           [64, 1280, 8, 8]           2,560\n",
      "           ReLU6-156           [64, 1280, 8, 8]               0\n",
      "         Dropout-157                 [64, 1280]               0\n",
      "          Linear-158                    [64, 2]           2,562\n",
      "================================================================\n",
      "Total params: 2,226,434\n",
      "Trainable params: 2,226,434\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 48.00\n",
      "Forward/backward pass size (MB): 12777.63\n",
      "Params size (MB): 8.49\n",
      "Estimated Total Size (MB): 12834.12\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = models.mobilenet_v2(pretrained=True)\n",
    "model.classifier[1] = nn.Linear(in_features=1280, out_features=2)\n",
    "model.to(device)\n",
    "summary(model, (3, 256, 256), batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.randn(1, 3, 256, 256).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/zhijian-liu/torchprofile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warm up the GPU\n",
    "with torch.no_grad():\n",
    "    for _ in range(10):\n",
    "        _ = model(input_tensor)\n",
    "\n",
    "# Measure FLOPs\n",
    "with torch.no_grad():\n",
    "    macs = torchprofile.profile_macs(model, args=(input_tensor,))\n",
    "    flops = 2 * macs  # Convert MACs to FLOPs\n",
    "\n",
    "# Measure inference time\n",
    "with torch.no_grad():\n",
    "    start_time = time.time()\n",
    "    for _ in range(100):  # Run multiple inferences\n",
    "        _ = model(input_tensor)\n",
    "    end_time = time.time()\n",
    "\n",
    "# Calculate elapsed time per inference and throughput\n",
    "elapsed_time = (end_time - start_time) / 100  # Average inference time per run\n",
    "tops = (flops / elapsed_time) / 1e12  # Throughput in TOPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLOPs: 0.80 GFLOPs, Inference Time: 9.10 ms, Throughput: 0.09 TOPs\n"
     ]
    }
   ],
   "source": [
    "print(f\"FLOPs: {flops / 1e9:.2f} GFLOPs, \"\n",
    "        f\"Inference Time: {elapsed_time * 1000:.2f} ms, Throughput: {tops:.2f} TOPs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt_fpad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
