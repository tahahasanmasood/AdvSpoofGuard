{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from torchvision import transforms, models\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label_live = 1\n",
    "class_label_print_attack_1 = 2\n",
    "class_label_print_attack_2 = 3\n",
    "class_label_display_attack_1 = 4\n",
    "class_label_display_attack_2 = 5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OULU-NPU Dataset Protocol I:  \n",
    "Training -> 1200 (Real 240, Attack 960) \\\n",
    "Validation -> 900 (Real 180, Attack 720) \\\n",
    "Testing -> 600 (Real 120, Attack 480)\n",
    "\n",
    "OULU-NPU Dataset Protocol II:  \n",
    "Training -> 1080 (Real 360, Attack 720) \\\n",
    "Validation -> 810 (Real 270, Attack 540) \\\n",
    "Testing -> 1080 (Real 360, Attack 720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_test_live = '/protocol_I/test/real'\n",
    "data_path_test_print_attack_1 = '/protocol_I/test/attack_sep/print1'\n",
    "data_path_test_print_attack_2 = '/protocol_I/test/attack_sep/print2'\n",
    "data_path_test_display_attack_1 = '/protocol_I/test/attack_sep/display1'\n",
    "data_path_test_display_attack_2 = '/protocol_I/test/attack_sep/display2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_samples(path, class_label, transform): #Select N frames returned from read_all_frames and assign labels to all samples of same class\n",
    "        frames = read_all_frames(path)\n",
    "        total_frames = list(range(0, frames.shape[0], 1))\n",
    "        selected_samples = 5\n",
    "        selected_frame = total_frames[selected_samples]\n",
    "        samples =[]\n",
    "        # Assign the same class label to all samples\n",
    "        label = class_label\n",
    "        samples =(transform(frames[selected_frame].squeeze()), label)     \n",
    "        return samples\n",
    "\n",
    "def read_all_frames(video_path): # reads all frames from a particular video and converts them to PyTorch tensors.\n",
    "    frame_list = []\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    success = True\n",
    "    while success:\n",
    "        success, frame = video.read()\n",
    "        if success:\n",
    "            frame = cv2.resize(frame, (256, 256), interpolation=cv2.INTER_AREA) #framesize kept 256 x 256 \n",
    "            frame_list.append(frame)\n",
    "    frame_list = np.array(frame_list)\n",
    "    return frame_list\n",
    "\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, data_path, class_label):\n",
    "        self.data_path = data_path #path for directory containing video files\n",
    "        self.video_files = [file for file in os.listdir(data_path) if file.endswith('.avi')]\n",
    "        self.class_label = class_label #manually assign class_label for your desired class while loading\n",
    "        self.data_length = len(self.video_files) \n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    def __len__(self): # returns the total number of samples in the dataset\n",
    "        return self.data_length\n",
    "\n",
    "    def __getitem__(self, idx): # loads and returns a sample from the dataset at the given index\n",
    "        file = self.video_files[idx]\n",
    "        path = os.path.join(self.data_path, file)\n",
    "        frames= load_samples(path, self.class_label, self.transform)\n",
    "\n",
    "        return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_live = VideoDataset(data_path_test_live, class_label_live)\n",
    "test_dataset_print_attack_1 = VideoDataset(data_path_test_print_attack_1, class_label_print_attack_1)\n",
    "test_dataset_print_attack_2 = VideoDataset(data_path_test_print_attack_2, class_label_print_attack_2)\n",
    "test_dataset_display_attack_1 = VideoDataset(data_path_test_display_attack_1, class_label_display_attack_1)\n",
    "test_dataset_display_attack_2 = VideoDataset(data_path_test_display_attack_2, class_label_display_attack_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_test_dataset = ConcatDataset([test_dataset_live, test_dataset_print_attack_1, test_dataset_print_attack_2, test_dataset_display_attack_1, test_dataset_display_attack_2])\n",
    "concatenated_test_loader = DataLoader(concatenated_test_dataset, batch_size=64, shuffle=False, pin_memory=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set size: 600\n"
     ]
    }
   ],
   "source": [
    "# Print dataset sizes\n",
    "print(f\"Test set size: {len(concatenated_test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taha/anaconda3/envs/pt_fpad/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/taha/anaconda3/envs/pt_fpad/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained MobileNetV2\n",
    "model = models.mobilenet_v2(pretrained=True)\n",
    "model.classifier[1] = nn.Linear(in_features=1280, out_features=2) #default in_features =1280, out_features = 1000\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Define the path to your saved model file\n",
    "model_path = '/OULUprotocols/protocol_I/OULUNPU_prot_I.pth' # before OULU_prot_I.pth after OULU_prot_I_FB.pth before OULU_prot_II.pth after OULU_prot_II_FB.pth \n",
    "\n",
    "# Load the saved model\n",
    "checkpoint = torch.load(model_path)\n",
    "\n",
    "# Load the model's state dictionary\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 1.00%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the test set\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    \n",
    "    test_cat_labels = torch.empty(0, dtype=torch.int64, device=device)\n",
    "    test_predicted_cat_labels = torch.empty(0, dtype=torch.int64, device=device)\n",
    "    test_model_op_cat = torch.empty(0, dtype=torch.int64, device=device)\n",
    "\n",
    "    for test_images, test_labels in concatenated_test_loader:\n",
    "        test_images, test_labels = test_images.to(device), test_labels.to(device)\n",
    "        test_model_op = model(test_images)\n",
    "        _, test_predicted = torch.max(test_model_op, 1)\n",
    "        test_correct += (test_predicted == test_labels).sum().item() \n",
    "        test_total += test_labels.size(0)\n",
    "\n",
    "        test_cat_labels = torch.cat((test_cat_labels, test_labels))\n",
    "        test_predicted_cat_labels = torch.cat((test_predicted_cat_labels, test_predicted))\n",
    "        test_model_op_cat = torch.cat((test_model_op_cat, test_model_op))\n",
    "\n",
    "    test_accuracy = test_correct / test_total * 100  \n",
    "    print(f'Test Accuracy: {test_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cat_labels_cpu = test_cat_labels.cpu()\n",
    "test_predicted_cat_labels_cpu = test_predicted_cat_labels.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "softmax_output = F.softmax(test_model_op_cat, dim=1)\n",
    "\n",
    "test_model_op_cat_second_column = softmax_output[:, 1]\n",
    "\n",
    "test_model_op_cat_second_column_cpu = test_model_op_cat_second_column.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subtracted because our labels are opposite as compared to oulumetrics\n",
    "\n",
    "our labels:\n",
    " 0 - live\n",
    " 1 - attack\n",
    "\n",
    " oulumetics:\n",
    " 1 - live\n",
    " 0 - attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9.9994e-01, 9.3744e-01, 9.9734e-01, 9.9999e-01, 9.9941e-01, 9.7976e-01,\n",
      "        7.7406e-01, 9.9987e-01, 9.9987e-01, 1.0000e+00, 9.9999e-01, 8.3714e-02,\n",
      "        9.0387e-01, 9.9916e-01, 9.9885e-01, 1.0000e+00, 9.0859e-01, 1.0000e+00,\n",
      "        1.0000e+00, 8.9238e-01, 9.9990e-01, 9.9585e-01, 8.8911e-01, 1.0000e+00,\n",
      "        9.9999e-01, 9.5694e-01, 9.9824e-01, 9.9997e-01, 9.9935e-01, 9.9996e-01,\n",
      "        9.9921e-01, 9.9759e-01, 9.8865e-01, 9.9970e-01, 9.4609e-01, 1.0000e+00,\n",
      "        9.9594e-01, 9.9948e-01, 9.9998e-01, 1.0000e+00, 5.5976e-01, 9.9994e-01,\n",
      "        9.9997e-01, 1.0000e+00, 9.9963e-01, 9.9773e-01, 9.9891e-01, 9.9994e-01,\n",
      "        7.5041e-01, 9.9938e-01, 6.4764e-01, 9.9934e-01, 7.6653e-01, 9.9527e-01,\n",
      "        9.9850e-01, 9.9999e-01, 9.9550e-01, 1.0000e+00, 8.4706e-01, 9.9738e-01,\n",
      "        9.0888e-01, 1.0000e+00, 9.8564e-01, 6.4391e-02, 9.9954e-01, 9.9419e-01,\n",
      "        9.9990e-01, 5.4730e-02, 9.9998e-01, 9.9992e-01, 9.9994e-01, 9.9991e-01,\n",
      "        9.9971e-01, 9.9999e-01, 9.9999e-01, 9.9960e-01, 9.9763e-01, 7.8632e-02,\n",
      "        9.8376e-01, 9.9980e-01, 9.9624e-01, 9.9978e-01, 6.6208e-01, 9.9932e-01,\n",
      "        9.9996e-01, 9.7887e-01, 9.9455e-01, 9.9748e-01, 9.8857e-01, 1.0000e+00,\n",
      "        9.8688e-01, 9.9989e-01, 3.8940e-01, 9.6718e-01, 9.9256e-01, 1.0000e+00,\n",
      "        9.9915e-01, 9.9999e-01, 9.9999e-01, 9.9567e-01, 9.7770e-01, 9.9996e-01,\n",
      "        1.0000e+00, 9.9993e-01, 9.9967e-01, 9.9064e-01, 1.0000e+00, 9.9997e-01,\n",
      "        9.9999e-01, 9.9997e-01, 9.9998e-01, 9.9918e-01, 9.9504e-01, 9.9974e-01,\n",
      "        1.9937e-01, 9.9326e-01, 9.9906e-01, 9.9923e-01, 9.9999e-01, 9.9560e-01,\n",
      "        2.9379e-04, 0.0000e+00, 1.2279e-05, 2.6591e-02, 6.1989e-06, 2.5113e-01,\n",
      "        1.6689e-06, 1.0371e-05, 0.0000e+00, 8.3447e-07, 0.0000e+00, 1.1206e-05,\n",
      "        2.3842e-06, 4.7016e-04, 1.8239e-05, 2.7418e-06, 4.7684e-07, 8.2850e-05,\n",
      "        1.5497e-06, 1.4305e-06, 5.9605e-06, 0.0000e+00, 9.2530e-04, 5.6368e-04,\n",
      "        3.5763e-06, 1.7881e-06, 1.3113e-05, 8.3447e-07, 0.0000e+00, 1.7881e-06,\n",
      "        5.4220e-03, 1.3859e-03, 1.8662e-04, 1.1373e-04, 1.5986e-04, 0.0000e+00,\n",
      "        0.0000e+00, 1.7709e-04, 4.5401e-04, 1.3816e-04, 7.0333e-06, 4.8876e-06,\n",
      "        4.8459e-02, 1.5020e-05, 1.3093e-03, 5.9605e-07, 9.5367e-07, 1.1921e-07,\n",
      "        2.0266e-06, 1.4960e-01, 2.1458e-06, 2.0146e-05, 6.3181e-06, 0.0000e+00,\n",
      "        2.0893e-03, 0.0000e+00, 9.2815e-03, 2.6387e-04, 4.7684e-07, 1.8698e-04,\n",
      "        0.0000e+00, 2.6077e-02, 4.7827e-04, 1.3387e-04, 1.0707e-02, 2.0808e-04,\n",
      "        4.7684e-07, 3.9339e-06, 1.8333e-03, 1.1921e-07, 1.8001e-05, 4.7926e-02,\n",
      "        5.9605e-07, 0.0000e+00, 4.7684e-07, 0.0000e+00, 1.5497e-06, 1.1921e-07,\n",
      "        5.8413e-05, 0.0000e+00, 2.0266e-06, 7.5340e-05, 2.5351e-02, 3.5763e-07,\n",
      "        5.4196e-01, 1.9073e-06, 5.6505e-05, 0.0000e+00, 1.1921e-06, 0.0000e+00,\n",
      "        8.3447e-06, 7.9632e-05, 5.3406e-05, 3.8445e-04, 4.2915e-06, 1.1921e-07,\n",
      "        3.9340e-03, 0.0000e+00, 1.9282e-02, 3.1650e-04, 1.1086e-05, 2.5034e-06,\n",
      "        1.4663e-05, 4.3631e-05, 1.3113e-06, 5.9605e-07, 6.8617e-03, 1.1635e-04,\n",
      "        0.0000e+00, 4.7684e-07, 4.7684e-07, 7.0795e-02, 0.0000e+00, 3.8862e-01,\n",
      "        1.0371e-04, 6.3658e-05, 1.5497e-06, 3.6836e-04, 2.8610e-06, 6.9141e-06,\n",
      "        1.3709e-05, 5.9605e-07, 2.2009e-01, 2.1547e-04, 8.0109e-03, 1.5497e-06,\n",
      "        1.4073e-02, 1.1921e-07, 0.0000e+00, 3.5763e-07, 1.8522e-01, 7.8082e-05,\n",
      "        7.1526e-07, 2.3842e-07, 9.5367e-07, 2.3842e-07, 5.9605e-07, 2.1935e-05,\n",
      "        4.9639e-04, 3.5763e-07, 1.9246e-04, 1.7285e-05, 5.2351e-04, 1.6827e-01,\n",
      "        2.0266e-06, 9.0122e-05, 4.4099e-02, 6.0987e-04, 9.2626e-05, 7.1063e-01,\n",
      "        6.4188e-04, 2.6387e-04, 2.1458e-06, 0.0000e+00, 2.3842e-06, 1.0729e-06,\n",
      "        2.2173e-05, 9.5367e-07, 3.6645e-04, 4.0647e-02, 0.0000e+00, 1.5497e-06,\n",
      "        0.0000e+00, 0.0000e+00, 1.1921e-07, 1.8766e-01, 1.1921e-07, 1.9073e-06,\n",
      "        6.1989e-06, 4.0531e-06, 0.0000e+00, 2.7418e-06, 9.5367e-07, 2.5749e-05,\n",
      "        7.2718e-06, 6.5295e-02, 4.3631e-05, 2.6226e-06, 1.6689e-05, 1.1815e-02,\n",
      "        9.7752e-06, 1.1921e-06, 1.7285e-05, 0.0000e+00, 1.2755e-05, 4.5300e-06,\n",
      "        1.1921e-07, 1.4305e-06, 2.1458e-06, 1.0729e-05, 0.0000e+00, 1.1921e-07,\n",
      "        7.1526e-07, 4.9901e-04, 1.9234e-04, 1.6689e-06, 0.0000e+00, 1.1921e-07,\n",
      "        2.5392e-05, 2.1656e-01, 7.0331e-03, 8.6427e-05, 7.1526e-07, 7.8741e-01,\n",
      "        1.1921e-07, 2.3842e-07, 4.5300e-06, 5.4836e-06, 2.8610e-06, 1.1921e-07,\n",
      "        9.2387e-05, 3.5763e-07, 1.3113e-06, 3.3379e-06, 2.2310e-04, 1.1921e-07,\n",
      "        0.0000e+00, 3.5763e-07, 2.5034e-06, 4.8423e-04, 1.1921e-07, 5.3644e-06,\n",
      "        6.4611e-05, 5.9605e-07, 2.3842e-07, 1.1921e-07, 4.7684e-07, 4.7684e-07,\n",
      "        1.3351e-05, 1.6093e-05, 1.3530e-04, 5.1260e-06, 0.0000e+00, 7.6921e-01,\n",
      "        4.7684e-07, 0.0000e+00, 2.0951e-04, 5.3644e-06, 7.1526e-07, 1.0252e-05,\n",
      "        4.7684e-07, 4.0412e-05, 1.8835e-05, 8.3447e-07, 3.5763e-07, 7.3069e-04,\n",
      "        0.0000e+00, 5.4836e-06, 1.1921e-07, 1.7405e-05, 1.9073e-06, 3.5644e-05,\n",
      "        0.0000e+00, 3.5763e-07, 2.8610e-06, 2.4277e-04, 6.9869e-04, 8.3447e-07,\n",
      "        9.5367e-06, 3.9339e-06, 1.1921e-07, 2.7353e-04, 2.3842e-07, 1.1921e-07,\n",
      "        9.5367e-07, 1.2517e-05, 1.0860e-03, 3.5763e-07, 2.6226e-06, 7.1526e-06,\n",
      "        0.0000e+00, 3.5763e-06, 0.0000e+00, 3.4571e-05, 1.6809e-05, 9.5367e-07,\n",
      "        7.2122e-05, 5.9605e-07, 1.4305e-06, 1.4305e-05, 2.3842e-07, 2.9564e-05,\n",
      "        2.3842e-07, 1.3828e-05, 1.1921e-07, 7.5579e-05, 9.4533e-05, 1.2994e-05,\n",
      "        4.4107e-06, 1.3396e-01, 3.7909e-05, 2.6226e-05, 0.0000e+00, 9.8526e-04,\n",
      "        2.8729e-05, 8.3447e-07, 7.5102e-06, 3.5763e-07, 3.6955e-06, 1.4591e-04,\n",
      "        2.2155e-04, 3.4571e-06, 6.4373e-06, 1.3590e-05, 9.1791e-06, 1.0610e-05,\n",
      "        1.3113e-06, 3.5763e-07, 2.8580e-04, 1.1921e-07, 6.2233e-04, 1.1921e-07,\n",
      "        8.4425e-03, 1.1444e-04, 4.0531e-05, 9.5367e-07, 1.1921e-07, 1.4305e-06,\n",
      "        1.5497e-06, 7.7486e-06, 3.2926e-04, 9.5367e-07, 0.0000e+00, 6.3181e-05,\n",
      "        2.0234e-02, 2.7537e-05, 2.3842e-07, 2.2650e-06, 7.6592e-04, 0.0000e+00,\n",
      "        3.5763e-07, 2.3049e-04, 9.2626e-05, 2.6941e-05, 5.5909e-05, 4.5735e-03,\n",
      "        1.4532e-04, 4.7684e-06, 8.3447e-07, 1.1921e-07, 6.4492e-05, 2.7418e-06,\n",
      "        8.3447e-07, 1.4186e-05, 4.7684e-07, 7.0310e-04, 5.1109e-03, 3.5763e-07,\n",
      "        8.4400e-05, 2.6363e-04, 3.7909e-05, 4.7684e-07, 1.1921e-07, 5.9605e-07,\n",
      "        1.4532e-03, 1.2040e-05, 1.6689e-06, 6.2371e-03, 7.1526e-07, 4.0293e-05,\n",
      "        1.4627e-04, 2.3842e-07, 7.1526e-07, 1.2982e-04, 1.1921e-07, 0.0000e+00,\n",
      "        1.3113e-06, 2.3842e-06, 5.8413e-06, 3.7799e-03, 1.1563e-05, 0.0000e+00,\n",
      "        1.2517e-05, 1.2434e-04, 5.8413e-06, 3.6609e-04, 2.9628e-03, 2.5511e-05,\n",
      "        5.0902e-05, 5.9605e-07, 2.6768e-04, 4.0970e-02, 0.0000e+00, 4.5300e-06,\n",
      "        8.2135e-05, 7.4822e-04, 3.8147e-06, 7.0000e-04, 1.1921e-07, 1.1921e-07,\n",
      "        8.4639e-06, 2.0266e-06, 3.2663e-05, 0.0000e+00, 2.6709e-04, 3.4571e-06,\n",
      "        1.1921e-07, 3.5066e-03, 1.6715e-03, 5.7578e-05, 2.0266e-06, 3.5763e-07,\n",
      "        2.8491e-05, 5.6028e-06, 3.8147e-05, 1.2708e-04, 1.7470e-04, 9.5367e-07,\n",
      "        2.5839e-04, 1.5736e-05, 4.7088e-05, 3.0518e-05, 2.5392e-05, 4.7302e-04,\n",
      "        1.3113e-06, 2.3842e-07, 1.0729e-05, 4.7684e-07, 3.4571e-06, 1.7881e-06,\n",
      "        1.1921e-07, 3.3379e-06, 5.9605e-07, 1.0471e-03, 1.1921e-07, 2.3484e-05,\n",
      "        3.7551e-05, 1.5497e-06, 4.7684e-07, 1.1921e-07, 4.7684e-07, 5.9605e-06,\n",
      "        1.1706e-04, 7.0333e-06, 3.4571e-06, 3.2663e-05, 1.3113e-06, 1.1921e-07,\n",
      "        1.1921e-07, 2.9206e-05, 4.7684e-07, 2.3842e-07, 1.2596e-02, 1.0729e-06,\n",
      "        0.0000e+00, 0.0000e+00, 2.3842e-07, 7.1526e-06, 2.9325e-05, 0.0000e+00,\n",
      "        1.4890e-02, 3.5869e-02, 1.9073e-06, 1.7881e-06, 1.2897e-03, 8.3447e-07,\n",
      "        5.1260e-06, 3.3391e-02, 8.5688e-04, 0.0000e+00, 8.3447e-07, 1.1921e-07,\n",
      "        1.0157e-04, 9.5367e-07, 0.0000e+00, 6.8665e-05, 2.4619e-03, 1.1921e-07,\n",
      "        8.2002e-02, 1.8239e-05, 0.0000e+00, 7.1526e-06, 8.8215e-06, 0.0000e+00,\n",
      "        1.2636e-05, 2.3842e-07, 8.5831e-06, 1.0729e-05, 3.7670e-05, 4.7684e-07])\n"
     ]
    }
   ],
   "source": [
    "subtracted = 1 - test_model_op_cat_second_column_cpu\n",
    "\n",
    "print(subtracted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softmax with Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016666666666666666\n",
      "0.05\n",
      "0.03333333333333333\n"
     ]
    }
   ],
   "source": [
    "import oulumetrics\n",
    "\n",
    "# returns the metrics APCER, BPCER and ACER\n",
    "apcer, bpcer, acer = oulumetrics.calculate_metrics(test_cat_labels_cpu, subtracted, 1-0.5868009924888611)\n",
    "\n",
    "print(apcer)\n",
    "print(bpcer)\n",
    "print(acer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016666666666666666\n",
      "0.05\n",
      "0.03333333333333333\n"
     ]
    }
   ],
   "source": [
    "import oulumetrics\n",
    "\n",
    "apcer, bpcer, acer = oulumetrics.calculate_metrics(test_cat_labels_cpu, 1-test_predicted_cat_labels)\n",
    "print(apcer)\n",
    "print(bpcer)\n",
    "print(acer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt_fpad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
