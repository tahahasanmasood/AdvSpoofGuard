{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from torchvision import transforms, models\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label_real = 0\n",
    "class_label_attack = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Synthetic Images Dataset Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_test_synthetic_images = '/folder/test_synthetic_images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for Loading Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_samples_image(image_path, class_label, transform):\n",
    "    image = Image.open(image_path).convert('RGB') # It uses PIL (Pillow) library to open the image, convert it to the RGB mode\n",
    "    sample = (transform(image), class_label) # Apply transformation\n",
    "    return sample\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data_path, class_label):\n",
    "        self.data_path = data_path\n",
    "        self.image_files = [file for file in os.listdir(data_path) if file.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        self.class_label = class_label\n",
    "        self.data_length = len(self.image_files)\n",
    "        self.transform = transforms.Compose([transforms.Resize((256, 256)),\n",
    "                                             transforms.ToTensor()])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file = self.image_files[idx]\n",
    "        path = os.path.join(self.data_path, file)\n",
    "        sample = load_samples_image(path, self.class_label, self.transform)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Dataset & Assigning Labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_attack_images = ImageDataset(data_path_test_synthetic_images, class_label_attack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Concatenation & Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader_attack_images = DataLoader(test_dataset_attack_images, batch_size=64, shuffle=False, pin_memory=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking Total No. of Samples for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print dataset sizes\n",
    "print(f\"Test set size: {len(test_dataset_attack_images)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained MobileNetV2\n",
    "model = models.mobilenet_v2(pretrained=True)\n",
    "model.classifier[1] = nn.Linear(in_features=1280, out_features=2) #default in_features =1280, out_features = 1000\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Define the path to your saved model file\n",
    "model_path = '/folder/bestmodel_fake.pth'\n",
    "\n",
    "# Load the saved model\n",
    "checkpoint = torch.load(model_path)\n",
    "\n",
    "# Load the model's state dictionary\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the test set\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    \n",
    "    test_cat_labels = torch.empty(0, dtype=torch.int64, device=device)\n",
    "    test_predicted_cat_labels = torch.empty(0, dtype=torch.int64, device=device)\n",
    "\n",
    "    for test_images, test_labels in test_loader_attack_images:\n",
    "        test_images, test_labels = test_images.to(device), test_labels.to(device)\n",
    "        test_model_op = model(test_images)\n",
    "        _, test_predicted = torch.max(test_model_op, 1)\n",
    "        test_correct += (test_predicted == test_labels).sum().item() \n",
    "        test_total += test_labels.size(0)\n",
    "\n",
    "        test_cat_labels = torch.cat((test_cat_labels, test_labels))\n",
    "        test_predicted_cat_labels = torch.cat((test_predicted_cat_labels, test_predicted))\n",
    "\n",
    "    test_accuracy = test_correct / test_total * 100  \n",
    "    print(f'Test Accuracy: {test_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cat_labels_cpu = test_cat_labels.cpu()\n",
    "test_predicted_cat_labels_cpu = test_predicted_cat_labels.cpu()\n",
    "print(test_cat_labels_cpu)\n",
    "print(len(test_cat_labels_cpu))\n",
    "print(test_predicted_cat_labels_cpu)\n",
    "print(len(test_predicted_cat_labels_cpu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, balanced_accuracy_score\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(test_cat_labels_cpu, test_predicted_cat_labels_cpu, labels=[0,1]).ravel()\n",
    "\n",
    "print(f'TN: {tn}, FP: {fp}, FN: {fn}, TP: {tp}')\n",
    "\n",
    "acc_score = accuracy_score(test_cat_labels_cpu, test_predicted_cat_labels_cpu)\n",
    "prec_score = precision_score(test_cat_labels_cpu, test_predicted_cat_labels_cpu)\n",
    "recall = recall_score(test_cat_labels_cpu, test_predicted_cat_labels_cpu)\n",
    "\n",
    "Y_I_val =(tp/(tp+fn)) + (tn/(tn+fp)) - 1\n",
    "sensitivity_val = tp / (tp + fn)\n",
    "specificity_val = tn / (tn + fp)\n",
    "f1score_val = 2 * tp / (2 * tp + fp + fn)\n",
    "FAR = fp/(fp + tn)\n",
    "FRR = fn/(fn + tp)\n",
    "HTER_val = (FAR + FRR)/2\n",
    "EER = (fp+fn)/(tn+fp+fn+tp)\n",
    "val_bacc = balanced_accuracy_score(test_cat_labels_cpu, test_predicted_cat_labels_cpu)\n",
    "\n",
    "\n",
    "print('Testing Results')\n",
    "print(30*'-')\n",
    "print('Acc:', acc_score, '\\nSen:', sensitivity_val, '\\nSpec:', specificity_val, '\\nYI:', Y_I_val, '\\nF1:', f1score_val, '\\nPrec:', prec_score, '\\nRecall:', recall, '\\nHTER:', HTER_val, '\\nEER:', EER, '\\nBACC:', val_bacc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt_fpad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
